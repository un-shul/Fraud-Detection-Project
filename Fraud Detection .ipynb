{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accredian Screening Round Assignment\n",
    "\n",
    "### Candidate Name: Anshul Choudhary (choudharyanshul@iitgn.ac.in)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### README: I have developed a model for predicting fraudulent transactions for a financial compacy using five different Machine Learning Algorithms. The details are in the code snippet given below. For easy code readabilty, I have tried to write step-wise code and include comments as many as possible everywhere. I have first written down the answers of the questions written under \"Candidate Expectations\" in the given assignment. I'm hopeful going through those answers will definetely make things more simpler. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data cleaning including missing values, outliers, and multi-collinearity.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- **Missing Values:** I checked for missing values and handled them by filling with the mean for numeric columns (`amount`, `oldbalanceOrg`, `newbalanceOrig`, `oldbalanceDest`, `newbalanceDest`).\n",
    "- **Outliers:** Outliers were identified and removed using the Interquartile Range (IQR) method. This involved calculating the lower and upper whiskers and filtering out values outside this range.\n",
    "- **Multi-Collinearity:** I examined the correlation matrix to identify and handle highly correlated features to reduce redundancy and improve model performance.\n",
    "\n",
    "### 2. Describe your fraud detection model in elaboration.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "My fraud detection model utilized multiple machine learning algorithms: Logistic Regression, Decision Tree, K-Nearest Neighbors, Support Vector Machine, and a Neural Network. The steps included:\n",
    "\n",
    "- **Data Preprocessing:** Data was normalized using MinMaxScaler to ensure all features were on a similar scale. The data was split into 65% for training and 35% for testing using `train_test_split`.\n",
    "- **Class Imbalance Handling:** I used the NearMiss technique to address the imbalance in the dataset.\n",
    "- **Model Training and Evaluation:** Each model was trained on the processed data, and performance was evaluated using metrics like ROC AUC Score, F1 Score, Confusion Matrix, and Classification Report.\n",
    "\n",
    "### 3. How did you select variables to be included in the model?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- **Feature Engineering:** I created new features such as balance differences (`balance_orig_diff` and `balance_dest_diff`).\n",
    "- **One-Hot Encoding:** The `type` column was converted into multiple binary columns (`type_CASH_OUT`, `type_DEBIT`, `type_PAYMENT`, `type_TRANSFER`).\n",
    "- **Correlation Analysis:** Features with high correlation were handled to reduce multi-collinearity.\n",
    "\n",
    "### 4. Demonstrate the performance of the model by using the best set of tools.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Here are the performance metrics for each model:\n",
    "\n",
    "#### Accuracy Scores:\n",
    "| Model                    | Accuracy   |\n",
    "|--------------------------|------------|\n",
    "| Logistic Regression      | 0.867652   |\n",
    "| Decision Tree            | 0.934783   |\n",
    "| K-Nearest Neighbors      | 0.983826   |\n",
    "| Support Vector Machine   | 0.968522   |\n",
    "| Neural Network           | 0.976348   |\n",
    "\n",
    "#### F1 Scores:\n",
    "| Model                    | F1 Score   |\n",
    "|--------------------------|------------|\n",
    "| Logistic Regression      | 0.869580   |\n",
    "| Decision Tree            | 0.937965   |\n",
    "| K-Nearest Neighbors      | 0.983704   |\n",
    "| Support Vector Machine   | 0.967753   |\n",
    "| Neural Network           | 0.976307   |\n",
    "\n",
    "#### Confusion Matrices:\n",
    "\n",
    "| Model                    | True Positive | True Negative | False Positive | False Negative |\n",
    "|--------------------------|---------------|---------------|----------------|----------------|\n",
    "| Logistic Regression      | 2537          | 2452          | 423            | 338            |\n",
    "| Decision Tree            | 2835          | 2540          | 335            | 40             |\n",
    "| K-Nearest Neighbors      | 2807          | 2850          | 25             | 68             |\n",
    "| Support Vector Machine   | 2716          | 2853          | 22             | 159            |\n",
    "| Neural Network           | 2802          | 2812          | 63             | 73             |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 5. What are the key factors that predict fraudulent customer?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Key factors identified were:\n",
    "- **Transaction Amount:** Higher amounts are more indicative of fraud.\n",
    "- **Balance Differences:** Significant differences in balances before and after transactions.\n",
    "- **Transaction Type:** Certain transaction types like `TRANSFER` and `CASH_OUT` are more prone to fraud.\n",
    "\n",
    "### 6. Do these factors make sense? If yes, How? If not, How not?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Yes, these factors make sense based on domain knowledge:\n",
    "- **Transaction Amount:** Large amounts are often targeted in fraud.\n",
    "- **Balance Differences:** Large discrepancies indicate unusual activities.\n",
    "- **Transaction Type:** Some types are inherently riskier and more susceptible to fraud.\n",
    "\n",
    "### 7. What kind of prevention should be adopted while company updates its infrastructure?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Preventive measures include:\n",
    "- **Real-time Monitoring:** Implement real-time transaction monitoring systems.\n",
    "- **Anomaly Detection:** Use advanced anomaly detection algorithms to flag suspicious activities.\n",
    "- **User Authentication:** Strengthen user authentication processes, such as multi-factor authentication.\n",
    "- **Regular Audits:** Conduct regular audits and reviews of transaction data to detect and prevent fraud.\n",
    "\n",
    "### 8. Assuming these actions have been implemented, how would you determine if they work?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Evaluation of Prevention Measures:\n",
    "- **Reduction in Fraudulent Transactions:** Track the number of fraudulent transactions over time to see if there is a reduction.\n",
    "- **Improvement in Detection Metrics:** Monitor metrics such as ROC AUC Score, Precision, Recall, and F1 Score to assess the effectiveness of the fraud detection model.\n",
    "- **User Feedback:** Collect feedback from users regarding the security and efficiency of the transaction process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Work Involved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "import imblearn\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# Load dataset\n",
    "file_path = '/Users/anshul/Downloads/Fraud.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning and Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Handle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical features\n",
    "payment_types = pd.get_dummies(df['type'], prefix='type', drop_first=True)\n",
    "df = pd.concat([df, payment_types], axis=1)\n",
    "df.drop('type', axis=1, inplace=True)\n",
    "\n",
    "# Convert encoded columns to int64\n",
    "df['type_CASH_OUT'] = df['type_CASH_OUT'].astype(np.int64)\n",
    "df['type_DEBIT'] = df['type_DEBIT'].astype(np.int64)\n",
    "df['type_PAYMENT'] = df['type_PAYMENT'].astype(np.int64)\n",
    "df['type_TRANSFER'] = df['type_TRANSFER'].astype(np.int64)\n",
    "\n",
    "df.drop(columns=['nameOrig', 'nameDest'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers\n",
    "def remove_outliers(df, col):\n",
    "    lower_quantile = df[col].quantile(0.25)\n",
    "    upper_quantile = df[col].quantile(0.75)\n",
    "    IQR = upper_quantile - lower_quantile\n",
    "    lower_whisker = lower_quantile - 1.5 * IQR\n",
    "    upper_whisker = upper_quantile + 1.5 * IQR\n",
    "    temp = df.loc[(df[col] > lower_whisker) & (df[col] < upper_whisker)]\n",
    "    return temp[col]\n",
    "\n",
    "# Remove outliers for specified columns\n",
    "df['amount'] = remove_outliers(df, 'amount')\n",
    "df['oldbalanceOrg'] = remove_outliers(df, 'oldbalanceOrg')\n",
    "df['newbalanceOrig'] = remove_outliers(df, 'newbalanceOrig')\n",
    "df['oldbalanceDest'] = remove_outliers(df, 'oldbalanceDest')\n",
    "df['newbalanceDest'] = remove_outliers(df, 'newbalanceDest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values by filling with mean for numeric columns\n",
    "columns_to_fill = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "for col in columns_to_fill:\n",
    "    if col in df.columns:\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "    else:\n",
    "        print(f\"Column '{col}' does not exist in the dataframe\")\n",
    "\n",
    "# Remove outliers for specified columns\n",
    "columns_to_check = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "for col in columns_to_check:\n",
    "    df[col] = remove_outliers(df, col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Handling Missing Values and Class Imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with missing values\n",
    "missing_columns = df.columns[df.isnull().any()]\n",
    "\n",
    "# Fill missing values for numeric columns\n",
    "for col in missing_columns:\n",
    "    if df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('isFraud', axis=1)\n",
    "y = df['isFraud']\n",
    "\n",
    "# Apply NearMiss for undersampling\n",
    "nm = NearMiss()\n",
    "X_nm, y_nm = nm.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 General Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nm, y_nm, test_size=0.35, stratify=y_nm, random_state=2022)\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Train and Evaluate Multiple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "ROC AUC Score: 0.8676521739130435\n",
      "F1 Score: 0.869580119965724\n",
      "Confusion Matrix:\n",
      " [[2452  423]\n",
      " [ 338 2537]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87      2875\n",
      "           1       0.86      0.88      0.87      2875\n",
      "\n",
      "    accuracy                           0.87      5750\n",
      "   macro avg       0.87      0.87      0.87      5750\n",
      "weighted avg       0.87      0.87      0.87      5750\n",
      "\n",
      "Accuracy Score: 0.8676521739130435\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Logistic Regression\")\n",
    "print('ROC AUC Score:', roc_auc_score(y_test, lr_pred))\n",
    "print('F1 Score:', f1_score(y_test, lr_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, lr_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, lr_pred))\n",
    "print('Accuracy Score:', accuracy_score(y_test, lr_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "ROC AUC Score: 0.9347826086956523\n",
      "F1 Score: 0.9379652605459057\n",
      "Confusion Matrix:\n",
      " [[2540  335]\n",
      " [  40 2835]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      2875\n",
      "           1       0.89      0.99      0.94      2875\n",
      "\n",
      "    accuracy                           0.93      5750\n",
      "   macro avg       0.94      0.93      0.93      5750\n",
      "weighted avg       0.94      0.93      0.93      5750\n",
      "\n",
      "Accuracy Score: 0.9347826086956522\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "dtree_pred = dtree.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Decision Tree Classifier\")\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, dtree_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, dtree_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, dtree_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dtree_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, dtree_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "ROC AUC Score: 0.9838260869565217\n",
      "F1 Score: 0.9837042228841774\n",
      "Confusion Matrix:\n",
      " [[2850   25]\n",
      " [  68 2807]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      2875\n",
      "           1       0.99      0.98      0.98      2875\n",
      "\n",
      "    accuracy                           0.98      5750\n",
      "   macro avg       0.98      0.98      0.98      5750\n",
      "weighted avg       0.98      0.98      0.98      5750\n",
      "\n",
      "Accuracy Score: 0.9838260869565217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"K-Nearest Neighbors\")\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, knn_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, knn_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, knn_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, knn_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, knn_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "ROC AUC Score: 0.9685217391304347\n",
      "F1 Score: 0.9677534295385711\n",
      "Confusion Matrix:\n",
      " [[2853   22]\n",
      " [ 159 2716]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      2875\n",
      "           1       0.99      0.94      0.97      2875\n",
      "\n",
      "    accuracy                           0.97      5750\n",
      "   macro avg       0.97      0.97      0.97      5750\n",
      "weighted avg       0.97      0.97      0.97      5750\n",
      "\n",
      "Accuracy Score: 0.9685217391304348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Support Vector Machine\")\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, svm_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, svm_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, svm_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, svm_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, svm_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.6360 - loss: 0.6370 - val_accuracy: 0.8717 - val_loss: 0.3920\n",
      "Epoch 2/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.8484 - loss: 0.3977 - val_accuracy: 0.9129 - val_loss: 0.2348\n",
      "Epoch 3/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.8984 - loss: 0.2636 - val_accuracy: 0.9265 - val_loss: 0.1657\n",
      "Epoch 4/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.9135 - loss: 0.2075 - val_accuracy: 0.9284 - val_loss: 0.1349\n",
      "Epoch 5/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.9183 - loss: 0.1677 - val_accuracy: 0.9349 - val_loss: 0.1136\n",
      "Epoch 6/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.9315 - loss: 0.1390 - val_accuracy: 0.9574 - val_loss: 0.1016\n",
      "Epoch 7/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.9380 - loss: 0.1295 - val_accuracy: 0.9574 - val_loss: 0.0936\n",
      "Epoch 8/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.9493 - loss: 0.1066 - val_accuracy: 0.9752 - val_loss: 0.0861\n",
      "Epoch 9/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.9586 - loss: 0.1049 - val_accuracy: 0.9616 - val_loss: 0.0818\n",
      "Epoch 10/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.9636 - loss: 0.0939 - val_accuracy: 0.9686 - val_loss: 0.0762\n",
      "Epoch 11/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.9574 - loss: 0.0957 - val_accuracy: 0.9761 - val_loss: 0.0712\n",
      "Epoch 12/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9664 - loss: 0.0845 - val_accuracy: 0.9757 - val_loss: 0.0692\n",
      "Epoch 13/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.9638 - loss: 0.0855 - val_accuracy: 0.9761 - val_loss: 0.0671\n",
      "Epoch 14/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.9628 - loss: 0.0870 - val_accuracy: 0.9752 - val_loss: 0.0649\n",
      "Epoch 15/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.9683 - loss: 0.0786 - val_accuracy: 0.9780 - val_loss: 0.0632\n",
      "Epoch 16/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.9676 - loss: 0.0764 - val_accuracy: 0.9738 - val_loss: 0.0619\n",
      "Epoch 17/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.9681 - loss: 0.0775 - val_accuracy: 0.9789 - val_loss: 0.0615\n",
      "Epoch 18/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.9712 - loss: 0.0750 - val_accuracy: 0.9775 - val_loss: 0.0597\n",
      "Epoch 19/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.9728 - loss: 0.0721 - val_accuracy: 0.9794 - val_loss: 0.0582\n",
      "Epoch 20/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.9740 - loss: 0.0692 - val_accuracy: 0.9785 - val_loss: 0.0602\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step\n",
      "Neural Network\n",
      "ROC AUC Score: 0.9763478260869566\n",
      "F1 Score: 0.9763066202090592\n",
      "Confusion Matrix:\n",
      " [[2812   63]\n",
      " [  73 2802]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      2875\n",
      "           1       0.98      0.97      0.98      2875\n",
      "\n",
      "    accuracy                           0.98      5750\n",
      "   macro avg       0.98      0.98      0.98      5750\n",
      "weighted avg       0.98      0.98      0.98      5750\n",
      "\n",
      "Accuracy Score: 0.9763478260869565\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "\n",
    "# Define the neural network model\n",
    "def create_nn_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "input_dim = X_train.shape[1]\n",
    "nn_model = create_nn_model(input_dim)\n",
    "\n",
    "# Train the model\n",
    "history = nn_model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "nn_pred_prob = nn_model.predict(X_test)\n",
    "nn_pred = (nn_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "# Evaluation Metrics\n",
    "print(\"Neural Network\")\n",
    "print('ROC AUC Score:', roc_auc_score(y_test, nn_pred))\n",
    "print('F1 Score:', f1_score(y_test, nn_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, nn_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, nn_pred))\n",
    "print('Accuracy Score:', accuracy_score(y_test, nn_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of ML Models:\n",
      "Predictive Accuracy of Logistic Regression: 86.77%\n",
      "Predictive Accuracy of K Neighbors Classifier: 98.38%\n",
      "Predictive Accuracy of Support Vector Classifier: 96.85%\n",
      "Predictive Accuracy of Decision Tree Classifier: 93.48%\n",
      "Predictive Accuracy of Nueral Network Model: 97.63%\n"
     ]
    }
   ],
   "source": [
    "# Performance of ML Models\n",
    "print(\"Performance of ML Models:\")\n",
    "print('Predictive Accuracy of Logistic Regression:', str(np.round(accuracy_score(y_test, lr_pred) * 100, 2)) + '%')\n",
    "print('Predictive Accuracy of K Neighbors Classifier:', str(np.round(accuracy_score(y_test, knn_pred) * 100, 2)) + '%')\n",
    "print('Predictive Accuracy of Support Vector Classifier:', str(np.round(accuracy_score(y_test, svm_pred) * 100, 2)) + '%')\n",
    "print('Predictive Accuracy of Decision Tree Classifier:', str(np.round(accuracy_score(y_test, dtree_pred) * 100, 2)) + '%')\n",
    "print('Predictive Accuracy of Nueral Network Model:', str(np.round(accuracy_score(y_test, nn_pred) * 100, 2)) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
